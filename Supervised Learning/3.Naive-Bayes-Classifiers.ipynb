{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strengths\n",
    "#### MultinomialNB and BernoulliNB\n",
    "- The algorithms also has an alpha value that controls the model complexity, a bigger value of alpha gets a less complex model.\n",
    "- The alpha value can be tuned to get the best model, but it is not critical to get a good model.\n",
    "- They are used for sparse data, like text classification.\n",
    "- MultinomialNB usually performs better than BernoulliNB, in particular if the dataset has many non-zero features.\n",
    "#### GaussianNB\n",
    "- The algorithm is very fast and can be used for large datasets.\n",
    "### Weaknesses\n",
    "- The predictions are not very accurate, because the algorithms assume that the features are independent, which is not true in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (1.15.1)\n",
      "Requirement already satisfied: matplotlib in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (3.10.0)\n",
      "Requirement already satisfied: pandas in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: mglearn in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scikit-learn in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from mglearn) (1.6.1)\n",
      "Requirement already satisfied: imageio in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from mglearn) (2.37.0)\n",
      "Requirement already satisfied: joblib in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from mglearn) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/uwo/Learning/Introduction-to-Machine-Learning-with-Python/.env/lib/python3.10/site-packages (from scikit-learn->mglearn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy scipy matplotlib pandas mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three kinds of NBCs implemented in scikit-learn:\n",
    "- Gaussian Naive Bayes\n",
    "- Bernoulli Naive Bayes\n",
    "- Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB\n",
    "Can be applied to any continuous data.\n",
    "\n",
    "### BernoulliNB\n",
    "Assumes binary data.\n",
    "\n",
    "### MultinomialNB\n",
    "assumes count data (i.e. that each feature represents an integer count of something, like how often a word appears in a sentence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BernoulliNB and MultinomialNB are mostly used in text data classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BernoulliNB Classifier\n",
    "\n",
    "Counts how often every feature of each class is not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "            [0,1,0,1],\n",
    "            [1,0,1,1],\n",
    "            [0,0,0,1],\n",
    "            [1,0,1,0]\n",
    "            ])\n",
    "y = np.array([0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts:\n",
      "{np.int64(0): array([0, 1, 0, 2]), np.int64(1): array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    # iterate over each class\n",
    "    # count (sum) entries of 1 per feature\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "print(\"Feature counts:\\n{}\".format(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It was the worst hour in my life, but DeepSeek explain me it <3*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to classes, class 0 and class 1. The class 0 has two vectors (first and thirst), then we separate the data in their respective classes and count how many times the word appears in the class.\n",
    "\n",
    "For class 0 we have the vectors [0,1,0,1] and [0,0,0,1], the we analize the columns and count how many times the word appears in the class.\n",
    "Then, we have the following table:\n",
    "\n",
    "Features:\n",
    "\n",
    "Col 0: [0,0] -> 0 appears two times and 1 appears zero times\n",
    "Col 1: [1,0] -> 0 appears one time and 1 appears one time\n",
    "Col 2: [0,0] -> 0 appears two times and 1 appears zero times\n",
    "Col 3: [1,1] -> 0 appears zero times and 1 appears two times\n",
    "\n",
    "For class 1 we have the vectors [1,0,1,1] and [1,0,1,0], then...\n",
    "\n",
    "Features:\n",
    "\n",
    "Col 0: [1,1] -> 0 appears zero time and 1 appears two times\n",
    "Col 1: [0,0] -> 0 appears two times and 1 appears zero times\n",
    "Col 2: [1,1] -> 0 appears zero time and 1 appears two times\n",
    "Col 3: [1,0] -> 0 appears one time and 1 appears one time\n",
    "\n",
    "Then if we count the number of times the 1 appears in the class we have the following table:\n",
    "\n",
    "| Feature | Class 0 | Class 1 |\n",
    "|---------|---------|---------|\n",
    "| 0       | 0       | 2       |\n",
    "| 1       | 1       | 0       |\n",
    "| 2       | 0       | 2       |\n",
    "| 3       | 2       | 1       |\n",
    "\n",
    "If we explain the code, we have the following:\n",
    "\n",
    "1.\n",
    "```python\n",
    "for label in np.unique(y)\n",
    "```\n",
    "We select the unique elements of the target vector, then as our vector is [0,1,0,1] we get [0,1] and iterate over them.\n",
    "\n",
    "2.\n",
    "```python\n",
    "y == label\n",
    "```\n",
    "It return the rows of the table that are of the class 0 or 1.\n",
    "i.e. if y = [0,1,0,1] and label = 0, then y == label = [True, False, True, False]\n",
    "\n",
    "3.\n",
    "```python\n",
    "X[y == label]\n",
    "```\n",
    "It returns the rows of the table that are of the class 0 or 1.\n",
    "i.e. if y = [0,1,0,1] and label = 0, then X[y == label] = [[0,1,0,1], [0,0,0,1]]\n",
    "\n",
    "4.\n",
    "```python\n",
    "np.sum(X[y == label], axis=0)\n",
    "```\n",
    "\n",
    "It sums the time that 1 appears in the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other two Naive Bayes classifiers are similar to this one, but they have some differences in the way they count the features.\n",
    "The MultinoialNB counts the average value value of each feature for each class.\n",
    "\n",
    "The GaussianNB is used for continuous data, so it calculates the mean and the standard deviation of each feature for each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
